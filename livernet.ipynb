{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aDgEmUoDIu3O"
   },
   "source": [
    "# LiverNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "g_89mzVAKAou",
    "outputId": "229db40a-04f5-423e-f8bd-81da9d749aca"
   },
   "outputs": [],
   "source": [
    "## Importing necessary libraries\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.models import load_model, Model\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.utils import conv_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C9KvmrlJK2mN"
   },
   "outputs": [],
   "source": [
    "# defining file paths for training, validation and test sets\n",
    "train_path = './data/Train/'\n",
    "val_path = './data/Validation/'\n",
    "test_path = './data/Test/'\n",
    "\n",
    "# initializing fixed parameters\n",
    "batch_size = 4\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "input_shape = (img_height , img_width , 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "SFlptWAPLC_1",
    "outputId": "8173cb47-b314-461b-a371-543de7cb59eb"
   },
   "outputs": [],
   "source": [
    "## initializing data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,horizontal_flip = True,vertical_flip = True)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle = True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle = True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nwSohKMar7M0"
   },
   "outputs": [],
   "source": [
    "def aspp(x,input_shape,out_stride):\n",
    "\n",
    "    \"\"\"\n",
    "        ASPP Block\n",
    "        \n",
    "        Arguments:\n",
    "        \n",
    "            x: input feature map to the ASPP block\n",
    "            input_shape: input shape of the feature map\n",
    "            out_stride: the output stride\n",
    "            \n",
    "        Returns: \n",
    "            \n",
    "            output feature map after processing\n",
    "    \"\"\"\n",
    "    \n",
    "    b0=Conv2D(256,(1,1),padding=\"same\",use_bias=False)(x)\n",
    "    b0=BatchNormalization()(b0)\n",
    "    b0=Activation(\"relu\")(b0)\n",
    "\n",
    "    b1=DepthwiseConv2D((3,3),dilation_rate=(2,2),padding=\"same\",use_bias=False)(x)\n",
    "    b1=BatchNormalization()(b1)\n",
    "    b1=Activation(\"relu\")(b1)\n",
    "    b1=Conv2D(256,(1,1),padding=\"same\",use_bias=False)(b1)\n",
    "    b1=BatchNormalization()(b1)\n",
    "    b1=Activation(\"relu\")(b1)\n",
    "\n",
    "    b2=DepthwiseConv2D((3,3),dilation_rate=(3,3),padding=\"same\",use_bias=False)(x)\n",
    "    b2=BatchNormalization()(b2)\n",
    "    b2=Activation(\"relu\")(b2)\n",
    "    b2=Conv2D(256,(1,1),padding=\"same\",use_bias=False)(b2)\n",
    "    b2=BatchNormalization()(b2)\n",
    "    b2=Activation(\"relu\")(b2)\t\n",
    "\n",
    "    b3=DepthwiseConv2D((3,3),dilation_rate=(4,4),padding=\"same\",use_bias=False)(x)\n",
    "    b3=BatchNormalization()(b3)\n",
    "    b3=Activation(\"relu\")(b3)\n",
    "    b3=Conv2D(256,(1,1),padding=\"same\",use_bias=False)(b3)\n",
    "    b3=BatchNormalization()(b3)\n",
    "    b3=Activation(\"relu\")(b3)\n",
    "\n",
    "    b5=DepthwiseConv2D((3,3),dilation_rate=(6,6),padding=\"same\",use_bias=False)(x)\n",
    "    b5=BatchNormalization()(b5)\n",
    "    b5=Activation(\"relu\")(b5)\n",
    "    b5=Conv2D(256,(1,1),padding=\"same\",use_bias=False)(b5)\n",
    "    b5=BatchNormalization()(b5)\n",
    "    b5=Activation(\"relu\")(b5)\n",
    "\n",
    "    # b5 = DepthwiseConv2D((3,3),dilation_rate=(6,6),padding=\"same\",use_bias=False)(x)\n",
    "\n",
    "\n",
    "    out_shape=int(input_shape[0]/out_stride)\n",
    "    b4=AveragePooling2D(pool_size=(out_shape,out_shape))(x)\n",
    "    b4=Conv2D(256,(1,1),padding=\"same\",use_bias=False)(b4)\n",
    "    b4=BatchNormalization()(b4)\n",
    "    b4=Activation(\"relu\")(b4)\n",
    "    b4=BilinearUpsampling((out_shape,out_shape))(b4)\n",
    "\n",
    "    x=Concatenate()([b4,b0,b1,b2,b3,b5])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "AJQnDAKYIzFH",
    "outputId": "39a04d6e-b617-4e2a-b88d-eee4a135914a"
   },
   "outputs": [],
   "source": [
    "def cbam_block(cbam_feature, ratio=8):\n",
    "   \n",
    "    \"\"\"\n",
    "        CBAM block\n",
    "        \n",
    "        Arguments:\n",
    "        \n",
    "            cbam_feature: input feature map to CBAM block\n",
    "            ratio: channel division ratio in channel attention module\n",
    "            \n",
    "        Returns:\n",
    "        \n",
    "            output feature map after processing in CBAM block\n",
    "    \"\"\"\n",
    "\n",
    "    cbam_feature = channel_attention(cbam_feature, ratio)\n",
    "    cbam_feature = spatial_attention(cbam_feature)\n",
    "    return cbam_feature\n",
    "\n",
    "def channel_attention(input_feature, ratio=8):\n",
    "    \n",
    "    \"\"\"\n",
    "        Channel attention module\n",
    "        \n",
    "        Arguments:\n",
    "            \n",
    "            input_feature: input feature map to channel attention module\n",
    "            ratio: channel reduction ratio\n",
    "            \n",
    "        Returns:\n",
    "        \n",
    "            the product of the channel attention map and input feature map \n",
    "    \"\"\"\n",
    "    \n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    channel = input_feature._keras_shape[channel_axis]\n",
    "    \n",
    "    shared_layer_one = Dense(channel//ratio,\n",
    "                             activation='relu',\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros')\n",
    "    shared_layer_two = Dense(channel,\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros')\n",
    "    \n",
    "    avg_pool = GlobalAveragePooling2D()(input_feature)    \n",
    "    avg_pool = Reshape((1,1,channel))(avg_pool)\n",
    "    assert avg_pool._keras_shape[1:] == (1,1,channel)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    assert avg_pool._keras_shape[1:] == (1,1,channel//ratio)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "    assert avg_pool._keras_shape[1:] == (1,1,channel)\n",
    "    \n",
    "    max_pool = GlobalMaxPooling2D()(input_feature)\n",
    "    max_pool = Reshape((1,1,channel))(max_pool)\n",
    "    assert max_pool._keras_shape[1:] == (1,1,channel)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    assert max_pool._keras_shape[1:] == (1,1,channel//ratio)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "    assert max_pool._keras_shape[1:] == (1,1,channel)\n",
    "    \n",
    "    cbam_feature = Add()([avg_pool,max_pool])\n",
    "    cbam_feature = Activation('sigmoid')(cbam_feature)\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "    \n",
    "    return multiply([input_feature, cbam_feature])\n",
    "\n",
    "def spatial_attention(input_feature):\n",
    "    \n",
    "    \"\"\"\n",
    "        Spatial attention module\n",
    "        \n",
    "        Arguments:\n",
    "            \n",
    "            input_feature: input feature map\n",
    "            \n",
    "        Returns:\n",
    "            \n",
    "            product of spatial attention map and input feature map\n",
    "    \"\"\"\n",
    "    \n",
    "    kernel_size = 7\n",
    "    \n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        channel = input_feature._keras_shape[1]\n",
    "        cbam_feature = Permute((2,3,1))(input_feature)\n",
    "    else:\n",
    "        channel = input_feature._keras_shape[-1]\n",
    "        cbam_feature = input_feature\n",
    "    \n",
    "    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    assert avg_pool._keras_shape[-1] == 1\n",
    "    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    assert max_pool._keras_shape[-1] == 1\n",
    "    concat = Concatenate(axis=3)([avg_pool, max_pool])\n",
    "    assert concat._keras_shape[-1] == 2\n",
    "    cbam_feature = Conv2D(filters = 1,\n",
    "                    kernel_size=kernel_size,\n",
    "                    strides=1,\n",
    "                    padding='same',\n",
    "                    activation='sigmoid',\n",
    "                    kernel_initializer='he_normal',\n",
    "                    use_bias=False)(concat)\t\n",
    "    assert cbam_feature._keras_shape[-1] == 1\n",
    "    \n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "        \n",
    "    return multiply([input_feature, cbam_feature])\n",
    "\n",
    "\n",
    "\n",
    "def residual_block(y, nb_channels, _strides=(1, 1), _project_shortcut=False):\n",
    "    \n",
    "    \"\"\"\n",
    "        Residual block (resnet block)\n",
    "        \n",
    "        Arguments: \n",
    "            \n",
    "            y: input feature map\n",
    "            nb_channels: number of channels\n",
    "            _strides: output strides\n",
    "            _project_shortcut: shortcut connection\n",
    "            \n",
    "        Returns:\n",
    "        \n",
    "            output feature map after processing\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "  shortcut = y\n",
    "\n",
    "  # down-sampling is performed with a stride of 2\n",
    "  y = Conv2D(nb_channels, kernel_size=(3, 3), strides=_strides, padding='same')(y)\n",
    "  y = BatchNormalization()(y)\n",
    "  y = LeakyReLU()(y)\n",
    "\n",
    "  y = Conv2D(nb_channels, kernel_size=(3, 3), strides=(1, 1), padding='same')(y)\n",
    "  y = BatchNormalization()(y)\n",
    "\n",
    "  # identity shortcuts used directly when the input and output are of the same dimensions\n",
    "  if _project_shortcut or _strides != (1, 1):\n",
    "    # when the dimensions increase projection shortcut is used to match dimensions (done by 1×1 convolutions)\n",
    "    # when the shortcuts go across feature maps of two sizes, they are performed with a stride of 2\n",
    "    shortcut = Conv2D(nb_channels, kernel_size=(1, 1), strides=_strides, padding='same')(shortcut)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "  y = add([shortcut, y])\n",
    "  y = LeakyReLU()(y)\n",
    "\n",
    "  return y\n",
    "\n",
    "\n",
    "class BilinearUpsampling(Layer):\n",
    "\n",
    "    \"\"\"\n",
    "        Bilinear Upsampling Class\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, upsampling=(2, 2), data_format=None, **kwargs):\n",
    "\n",
    "        \"\"\"\n",
    "            Constructor of Bilinear-Upsampling\n",
    "        \"\"\"\n",
    "        \n",
    "        super(BilinearUpsampling, self).__init__(**kwargs)\n",
    "        self.data_format = K.normalize_data_format(data_format)\n",
    "        self.upsampling = conv_utils.normalize_tuple(upsampling, 2, 'size')\n",
    "        self.input_spec = InputSpec(ndim=4)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        height = self.upsampling[0] * \\\n",
    "            input_shape[1] if input_shape[1] is not None else None\n",
    "        width = self.upsampling[1] * \\\n",
    "            input_shape[2] if input_shape[2] is not None else None\n",
    "        return (input_shape[0],\n",
    "                height,\n",
    "                width,\n",
    "                input_shape[3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.image.resize(inputs, (int(inputs.shape[1]*self.upsampling[0]),\n",
    "                                                   int(inputs.shape[2]*self.upsampling[1])))\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'size': self.upsampling,\n",
    "                  'data_format': self.data_format}\n",
    "        base_config = super(BilinearUpsampling, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    \n",
    "    \"\"\"\n",
    "        Method to create the final model\n",
    "    \"\"\"\n",
    "    \n",
    "    dropRate = 0.3\n",
    "    \n",
    "    init = Input((224,224,3))\n",
    "    x = Conv2D(32, (3, 3), activation=None, padding='same')(init) \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(32, (3, 3), activation=None, padding='same')(x) \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x1 = MaxPooling2D((2,2))(x)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), activation=None, padding='same')(x1)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = cbam_block(x)\n",
    "    x = residual_block(x, 64)\n",
    "    x2 = MaxPooling2D((2,2))(x)\n",
    "    \n",
    "    x = Conv2D(128, (3, 3), activation=None, padding='same')(x2)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = cbam_block(x)\n",
    "    x = residual_block(x, 128)\n",
    "    x3 = MaxPooling2D((2,2))(x)\n",
    "    \n",
    "    x1_aspp = aspp(x1,(112,112),1)\n",
    "    x2_aspp = aspp(x2,(56,56),1)\n",
    "    x3_aspp = aspp(x3,(28,28),1)\n",
    "\n",
    "    ginp1 = UpSampling2D(size=(2, 2), interpolation='bilinear')(x1_aspp)\n",
    "    ginp2 = UpSampling2D(size=(4, 4), interpolation='bilinear')(x2_aspp)\n",
    "    ginp3 = UpSampling2D(size=(8, 8), interpolation='bilinear')(x3_aspp)\n",
    "    \n",
    "    hypercolumn = Concatenate()([ginp1, ginp2, ginp3]) \n",
    "    gap = GlobalAveragePooling2D()(hypercolumn)\n",
    "\n",
    "    x = Dense(256, activation=None)(gap)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(dropRate)(x)\n",
    "    \n",
    "    x = Dense(256, activation=None)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    y = Dense(4, activation='softmax')(x)\n",
    "   \n",
    "    model = Model(init, y)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "for layer in model.layers:\n",
    "    if hasattr(layer, 'kernel_regularizer'):\n",
    "        layer.kernel_regularizer= regularizers.l2(0.003)\n",
    "    \n",
    "    if hasattr(layer, 'bias_regularizer'):\n",
    "        layer.bias_regularizer= regularizers.l2(0.003)\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(lr = 0.00001)\n",
    "\n",
    "from keras.optimizers import TFOptimizer\n",
    "learning_rate = K.variable(0.001)\n",
    "\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = [\"acc\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IF0owR5SJrQR",
    "outputId": "3b2c9e8a-1819-4d27-b5cf-b6cdc8fccfde"
   },
   "outputs": [],
   "source": [
    "## initialize call backs and train the model\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss' ,\n",
    "                                                  factor = 0.1 , patience = 3 , verbose=1 , cooldown = 1)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss' , min_delta = 0.001, patience = 7,\n",
    "                                                  verbose = 1, mode = 'min')\n",
    "\n",
    "history = model.fit_generator(train_generator , validation_data = validation_generator , \n",
    "                                  steps_per_epoch= len(train_generator) ,\n",
    "                                  validation_steps = len(validation_generator)\n",
    "                                  ,epochs = 40,callbacks = [reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "35ySXFUkL5zK",
    "outputId": "70eb9114-4dda-4fe2-bcbb-5c58cf9315c2"
   },
   "outputs": [],
   "source": [
    "## Plot the loss\n",
    "\n",
    "plt.plot(history.history['loss'] , label = 'train_loss')\n",
    "plt.plot(history.history['val_loss'] , label = 'val_loss')\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "1rPvykyeuqro",
    "outputId": "4062ec02-63b9-491e-e97b-bc06bd81af93"
   },
   "outputs": [],
   "source": [
    "## Plot the accuracy\n",
    "\n",
    "plt.plot(history.history['acc'] , label = 'train_acc')\n",
    "plt.plot(history.history['val_acc'] , label = 'val_acc')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "BSOItyzjupQv",
    "outputId": "77061f17-c6bc-4949-9c0a-b2ebb383d48e"
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=1,\n",
    "    shuffle = False,\n",
    "    class_mode='categorical')\n",
    "\n",
    "## printing ground truth labels\n",
    "print(test_generator.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "1ividG2sMzE-",
    "outputId": "4b353674-7806-45c3-9238-3a1a9317823e"
   },
   "outputs": [],
   "source": [
    "test_step = test_generator.n//test_generator.batch_size\n",
    "test_generator.reset()\n",
    "pred = model.predict_generator(test_generator , steps = test_step , verbose = 1)\n",
    "pred_class_indices = np.argmax(pred,axis=1)\n",
    "\n",
    "## printing predicted labels\n",
    "print(pred_class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "colab_type": "code",
    "id": "545-w1ONNb_5",
    "outputId": "89ac51b8-c9d0-4853-f41d-697a00297cbf"
   },
   "outputs": [],
   "source": [
    "## Classwise performance analysis\n",
    "\n",
    "classes = [0,1,2,3]\n",
    "\n",
    "\n",
    "for cl in classes:\n",
    "\n",
    "    print(\"class: \",cl)\n",
    "\n",
    "    a1 = np.uint8(test_generator.labels == cl)\n",
    "    a2 = np.uint8(pred_class_indices == cl)\n",
    "\n",
    "    print('Accuracy {}'.format(accuracy_score(y_true=a1, y_pred=a2)))\n",
    "    print('F1 {}'.format(f1_score(y_true=a1, y_pred=a2)))\n",
    "    print('precision {}'.format(precision_score(y_true=a1, y_pred=a2)))\n",
    "    print('recall {}'.format(recall_score(y_true=a1, y_pred=a2)))\n",
    "\n",
    "    print('jaccard {}'.format(jaccard_score(y_true=a1, y_pred=a2)))\n",
    "    print(\"_______________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "colab_type": "code",
    "id": "lciwXvVRM02G",
    "outputId": "389c19d7-f862-4ca8-e7ad-058808aaa2f6"
   },
   "outputs": [],
   "source": [
    "## Overall performance analysis\n",
    "\n",
    "from sklearn.metrics import accuracy_score,roc_curve, confusion_matrix, roc_auc_score, auc, f1_score,jaccard_score,classification_report\n",
    "from sklearn.metrics import precision_score,recall_score,jaccard_score\n",
    "\n",
    "print('Accuracy {}'.format(accuracy_score(y_true=test_generator.labels, y_pred=pred_class_indices)))\n",
    "print('F1 {}'.format(f1_score(y_true=test_generator.labels, y_pred=pred_class_indices,average = \"macro\")))\n",
    "print('precision {}'.format(precision_score(y_true=test_generator.labels, y_pred=pred_class_indices,average = \"macro\")))\n",
    "print('recall {}'.format(recall_score(y_true=test_generator.labels, y_pred=pred_class_indices,average = \"macro\")))\n",
    "\n",
    "print('jaccard {}'.format(jaccard_score(y_true=test_generator.labels, y_pred=pred_class_indices,average = \"macro\")))\n",
    "print('confusion_matrix\\n {}'.format(confusion_matrix(y_true=test_generator.labels, y_pred=pred_class_indices)))\n",
    "print('classification_report\\n {}'.format(classification_report(y_true=test_generator.labels, y_pred=pred_class_indices)))\n",
    "print('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of breastnet_aspp_tf2",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
